"""
Centralized staging handler for entity and customer extraction.

This module provides reusable functions for extracting, previewing, and importing
customer and entity staging data across File History, PRA, and PIC imports.
"""

import logging
import re
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

from app.models.database import CustomerStaging, EntityStaging, SessionLocal
from app.services.file_indexing_service import (
    _classify_customer_type,
    _extract_entity_name,
    _extract_customer_name,
    _extract_customer_address,
    _extract_photos,
    _combine_location,
    _generate_customer_code,
    _normalize_string,
    _strip_all_whitespace,
)

logger = logging.getLogger(__name__)

# Pattern to detect file numbers like CON-2004-56, RES-RC-1988-68, etc.
FILE_NUMBER_PATTERN = re.compile(r'^[A-Z]{2,}[-/][A-Z0-9]{1,}[-/][A-Z0-9]{1,}', re.IGNORECASE)

# Canonical transaction types permitted for reason_retired values
REASON_RETIRED_ALIAS_MAP = {
    'assignment': 'Assignment',
    'deed of assignment': 'Assignment',
    'withdrawn': 'Withdrawn',
    'withdraw': 'Withdrawn',
    'withdrawal': 'Withdrawn',
    'sub division': 'Sub Division',
    'subdivision': 'Sub Division',
    'subdivided': 'Sub Division',
    'sub divide': 'Sub Division',
    'menger': 'Menger',
    'surrender': 'Surrender',
    'revocation': 'Revocation',
    'revoked': 'Revocation',
}


def _normalize_reason_retired_key(value: str) -> str:
    """Normalize transaction text for reason_retired comparisons."""
    lowered = value.lower()
    lowered = lowered.replace('_', ' ')
    lowered = lowered.replace('-', ' ')
    cleaned = re.sub(r'[^a-z0-9\s]', ' ', lowered)
    cleaned = re.sub(r'\s+', ' ', cleaned)
    return cleaned.strip()


def _canonical_reason_retired(value: Optional[str]) -> Optional[str]:
    """Return canonical reason_retired if value matches allowed transaction types."""
    if not value:
        return None

    normalized_key = _normalize_reason_retired_key(value)
    if not normalized_key:
        return None

    tokens = normalized_key.split()

    for alias, canonical in REASON_RETIRED_ALIAS_MAP.items():
        alias_tokens = alias.split()
        if normalized_key == alias:
            return canonical
        if normalized_key.startswith(f"{alias} "):
            return canonical
        if alias in normalized_key:
            return canonical
        if len(alias_tokens) == 1 and alias_tokens[0] in tokens:
            return canonical
        if len(alias_tokens) > 1:
            window = len(alias_tokens)
            for idx in range(len(tokens) - window + 1):
                if tokens[idx: idx + window] == alias_tokens:
                    return canonical

    return None


def _looks_like_file_number(value: Optional[str]) -> bool:
    """
    Check if a value looks like a file number (e.g., CON-2004-56, RES-RC-1988-68).
    Also detects "File: RES-RC-1988-68" format.
    
    Returns True if the value matches file number patterns and should NOT be treated
    as an entity or customer name.
    """
    if not value:
        return False
    
    normalized = _normalize_string(value)
    if not normalized:
        return False
    
    # Check if it starts with "File: " prefix (generated by _extract_entity_name)
    if normalized.startswith("File:"):
        return True
    
    # Must contain at least one digit
    if not any(char.isdigit() for char in normalized):
        return False
    
    # Must contain separator (dash or slash)
    if not any(sep in normalized for sep in {'-', '/'}):
        return False
    
    # Check against file number pattern
    if FILE_NUMBER_PATTERN.match(normalized):
        return True
    
    # Additional check: if it's all uppercase with dashes/slashes and numbers
    stripped = _strip_all_whitespace(normalized).upper()
    parts = re.split(r'[-/]', stripped)
    
    # File numbers typically have 2-5 parts separated by dashes/slashes
    if 2 <= len(parts) <= 5:
        # At least one part should have digits
        has_digit_part = any(any(c.isdigit() for c in part) for part in parts)
        # Parts should be alphanumeric
        all_alphanumeric = all(part.replace('-', '').replace('/', '').isalnum() for part in parts if part)
        
        if has_digit_part and all_alphanumeric:
            return True
    
    return False


def _extract_reason_retired(
    record: Dict[str, Any],
    transaction_type_field: str = 'transaction_type'
) -> Optional[str]:
    """
    Extract a reason_retired value constrained to the supported transaction types.

    Allowed canonical values: Assignment, Withdrawn, Sub Division, Menger, Surrender, Revocation.
    Variations (e.g. "sub-division", "revoked", "withdrawal") are normalized to the
    corresponding canonical value. Any other transaction type returns None.
    """
    transaction_type = _normalize_string(record.get(transaction_type_field))
    return _canonical_reason_retired(transaction_type)


def _resolve_file_history_holder(record: Dict[str, Any], role: str) -> Optional[str]:
    """Resolve assignor/assignee style values that appear under multiple headers."""
    if role == 'assignor':
        candidate_fields = (
            'Assignor', 'Grantor', 'Original Holder (Assignor)',
            'Original Holder', 'original_holder_assignor', 'grantor_assignor'
        )
    else:
        candidate_fields = (
            'Assignee', 'Grantee', 'Current Holder (Assignee)',
            'Current Holder', 'current_holder_assignee', 'grantee_assignee'
        )

    for field in candidate_fields:
        resolved = _normalize_string(record.get(field))
        if resolved:
            return resolved
    return None


def _compose_reason_retired_detail(base_reason: Optional[str], assignee: Optional[str]) -> Optional[str]:
    """Build a human-friendly reason_retired description that references the assignee when present."""
    if base_reason and assignee:
        return f"{base_reason} -> {assignee}"
    if assignee:
        return assignee
    return base_reason


def extract_entity_and_customer_data(
    records: List[Dict[str, Any]],
    filename: str,
    test_control: str = 'PRODUCTION',
    transaction_type_field: str = 'transaction_type',
    source: str = 'default'
) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]], Dict[str, Any]]:
    """
    Extract entity and customer staging data from records.

    Returns: (entity_records, customer_records, summary)
    """

    entity_records: List[Dict[str, Any]] = []
    customer_records: List[Dict[str, Any]] = []
    entity_cache: Dict[str, int] = {}
    type_counter: Dict[str, int] = {}

    normalized_source = (source or 'default').strip().lower()
    is_file_history = normalized_source == 'file_history'
    is_pic = normalized_source == 'pic'
    is_pra = normalized_source == 'pra'

    for idx, record in enumerate(records):
        try:
            assignor = _resolve_file_history_holder(record, 'assignor') if is_file_history else None
            assignee = _resolve_file_history_holder(record, 'assignee') if is_file_history else None
            pic_grantor = _normalize_string(record.get('Grantor')) if is_pic else None
            pic_grantee = _normalize_string(record.get('grantee_original') or record.get('Grantee')) if is_pic else None
            pic_property_address = _normalize_string(record.get('property_description')) if is_pic else None
            pra_grantee = _normalize_string(record.get('grantee_assignee') or record.get('Grantee')) if is_pra else None
            pra_grantor = _normalize_string(record.get('grantor_assignor') or record.get('Grantor')) if is_pra else None
            transaction_label = _normalize_string(record.get(transaction_type_field)) if transaction_type_field else None
            location_value = _normalize_string(record.get('location'))
            district_value = record.get('districtName') or record.get('district')
            lga_value = record.get('LGA') or record.get('lga')
            pra_combined_location = _combine_location(district_value, lga_value) if is_pra else None

            # Determine base entity name using source-specific mapping
            entity_name = None
            if is_file_history:
                candidate = assignee or assignor
                # Skip if it looks like a file number
                if candidate and not _looks_like_file_number(candidate):
                    entity_name = candidate
            elif is_pic and pic_grantee:
                # Skip if grantee looks like a file number
                if not _looks_like_file_number(pic_grantee):
                    entity_name = pic_grantee
            elif is_pra and pra_grantee:
                # Skip if grantee looks like a file number
                if not _looks_like_file_number(pra_grantee):
                    entity_name = pra_grantee
            
            # Try extracting from record if not found yet
            if not entity_name:
                candidate = _extract_entity_name(record)
                if candidate and not _looks_like_file_number(candidate):
                    entity_name = candidate
            
            # Skip this record if entity name looks like a file number or is missing
            if not entity_name:
                logger.warning("No valid entity name for record %d (skipped file number pattern)", idx)
                continue

            descriptor_candidates = [
                entity_name,
                pic_grantee if is_pic else None,
                pic_grantor if is_pic else None,
                pra_grantee if is_pra else None,
                pra_grantor if is_pra else None,
                assignee if is_file_history else None,
                assignor if is_file_history else None,
                _normalize_string(record.get('file_title')),
                _normalize_string(record.get('customer_name')),
                filename
            ]

            descriptor = next((candidate for candidate in descriptor_candidates if candidate), filename)
            customer_type = _classify_customer_type(descriptor)
            type_counter[customer_type] = type_counter.get(customer_type, 0) + 1

            passport_photo, company_logo = _extract_photos(
                record,
                customer_type,
                include_placeholders=True
            )

            file_number_value = _normalize_string(
                record.get('file_number')
                or record.get('mlsFNo')
                or record.get('fileno')
                or record.get('fileNumber')
                or record.get('MLSFileNo')
            )

            cache_key = f"{entity_name}:{customer_type}"
            if cache_key not in entity_cache:
                next_entity_id = len(entity_records) + 1
                entity_data = {
                    'entity_id': next_entity_id,
                    'entity_name': entity_name,
                    'name': entity_name,
                    'entity_type': customer_type,
                    'passport_photo': passport_photo,
                    'company_logo': company_logo,
                    'file_number': file_number_value,
                    'status': 'new',
                    'test_control': test_control
                }
                entity_records.append(entity_data)
                entity_cache[cache_key] = len(entity_records) - 1
            else:
                existing_entity = entity_records[entity_cache[cache_key]]
                existing_entity['status'] = 'reused'
                if file_number_value and not existing_entity.get('file_number'):
                    existing_entity['file_number'] = file_number_value

            entity_index = entity_cache[cache_key]
            entity_id_value = entity_records[entity_index].get('entity_id')

            # Extract customer name, skipping file number patterns
            customer_name = None
            if is_file_history:
                if assignee and not _looks_like_file_number(assignee):
                    customer_name = assignee
                elif assignor and not _looks_like_file_number(assignor):
                    customer_name = assignor
                else:
                    candidate = _extract_customer_name(record, entity_name)
                    if candidate and not _looks_like_file_number(candidate):
                        customer_name = candidate
            elif is_pic and pic_grantee and not _looks_like_file_number(pic_grantee):
                customer_name = pic_grantee
            elif is_pra and pra_grantee and not _looks_like_file_number(pra_grantee):
                customer_name = pra_grantee
            else:
                candidate = _extract_customer_name(record, entity_name)
                if candidate and not _looks_like_file_number(candidate):
                    customer_name = candidate
            
            # Use entity_name as fallback if customer_name is invalid
            if not customer_name:
                customer_name = entity_name
            
            customer_code = _generate_customer_code()

            if is_file_history:
                property_address = location_value or _extract_customer_address(record)
            elif is_pic:
                combined_location = _combine_location(district_value, lga_value)
                property_address = combined_location or pic_property_address or _extract_customer_address(record)
            elif is_pra:
                property_address = pra_combined_location or _extract_customer_address(record)
            else:
                property_address = _extract_customer_address(record)

            if is_file_history:
                reason_retired_value = _canonical_reason_retired(transaction_label)
                reason_by_value = assignor
                notes_value = None
            elif is_pic:
                reason_retired_value = _canonical_reason_retired(transaction_label)
                reason_by_value = pic_grantor
                notes_value = None
            elif is_pra:
                reason_retired_value = _canonical_reason_retired(transaction_label)
                reason_by_value = pra_grantor
                notes_value = None
            else:
                reason_retired_value = _extract_reason_retired(record, transaction_type_field)
                reason_by_value = None
                notes_value = None

            status_value = 'Active' if not reason_retired_value else 'Retired'

            customer_data = {
                'customer_name': customer_name,
                'customer_type': customer_type,
                'status': status_value,
                'customer_code': customer_code,
                'email': _normalize_string(record.get('email')),
                'phone': _normalize_string(record.get('phone')),
                'property_address': property_address,
                'residential_address': _normalize_string(record.get('residential_address')),
                'notes': notes_value,
                'entity_name': entity_name,
                'entity_id': entity_id_value,
                'file_number': file_number_value,
                'account_no': file_number_value,
                'reason_retired': reason_retired_value,
                'reason_by': reason_by_value,
                'has_issues': False,
                'test_control': test_control,
                'created_by_raw': record.get('created_by')
            }
            customer_data['name'] = customer_name
            customer_data['transaction_type'] = transaction_label

            # If no reason_retired, clear reason_by to avoid showing it alone
            if not customer_data['reason_retired']:
                customer_data['reason_by'] = None

            customer_records.append(customer_data)

        except Exception as exc:  # pragma: no cover - defensive logging
            logger.warning("Error extracting staging data for record %d: %s", idx, str(exc))
            continue

    if not type_counter:
        summary_customer_type = _classify_customer_type(filename)
    elif len(type_counter) == 1:
        summary_customer_type = next(iter(type_counter))
    else:
        summary_customer_type = 'Mixed'

    staging_summary = {
        'customer_type': summary_customer_type,
        'customer_type_breakdown': type_counter,
        'entity_count': len(entity_records),
        'customer_count': len(customer_records),
        'new_entities': len([e for e in entity_records if e['status'] == 'new']),
        'existing_entities': len([e for e in entity_records if e['status'] == 'reused']),
        'duplicates_flagged': 0,
        'reason_retired_populated': len([c for c in customer_records if c.get('reason_retired')])
    }

    if normalized_source in {'file_history', 'pic', 'pra'}:
        latest_customer_index_by_file: Dict[str, int] = {}
        for index, customer in enumerate(customer_records):
            file_key = _normalize_string(customer.get('file_number'))
            if not file_key:
                continue
            latest_customer_index_by_file[file_key] = index

        staging_summary['reason_retired_populated'] = len([c for c in customer_records if c.get('reason_retired')])

    return entity_records, customer_records, staging_summary


def build_staging_preview(
    entity_records: List[Dict[str, Any]],
    customer_records: List[Dict[str, Any]],
    staging_summary: Dict[str, Any]
) -> Dict[str, Any]:
    """Build staging preview payload for response."""
    return {
        'entity_staging_preview': entity_records,
        'customer_staging_preview': customer_records,
        'staging_summary': staging_summary
    }


def perform_staging_import(
    db,
    records: List[Dict[str, Any]],
    filename: str,
    test_control: str = 'PRODUCTION',
    transaction_type_field: str = 'transaction_type',
    source: str = 'default',
    precomputed_entities: Optional[List[Dict[str, Any]]] = None,
    precomputed_customers: Optional[List[Dict[str, Any]]] = None
) -> Dict[str, Any]:
    """
    Perform actual staging import to database.
    
    Returns: {success, entity_summary, customer_summary, errors}
    """
    entity_summary = {
        'new': 0,
        'reused': 0,
        'failed': 0
    }
    
    customer_summary = {
        'created': 0,
        'failed': 0
    }
    
    entity_cache: Dict[str, EntityStaging] = {}
    errors: List[Dict[str, Any]] = []

    normalized_source = (source or 'default').strip().lower()
    is_file_history = normalized_source == 'file_history'
    is_pic = normalized_source == 'pic'
    is_pra = normalized_source == 'pra'

    staging_entities = precomputed_entities
    staging_customers = precomputed_customers

    staging_summary: Optional[Dict[str, Any]] = None
    if staging_entities is None or staging_customers is None:
        staging_entities, staging_customers, staging_summary = extract_entity_and_customer_data(
            records,
            filename,
            test_control,
            transaction_type_field=transaction_type_field,
            source=source
        )

    def build_entity_key(name: Optional[str], customer_type: Optional[str]) -> Optional[str]:
        normalized_name = _normalize_string(name)
        if not normalized_name:
            return None
        normalized_type = (customer_type or 'Individual')
        return f"{normalized_name}::{normalized_type}"
    
    def safe_int_conversion(value: Any) -> Optional[int]:
        """Convert possible numeric values to int, otherwise None."""
        if value is None:
            return None
        if isinstance(value, int):
            return value
        try:
            str_value = str(value).strip()
            if not str_value:
                return None
            return int(str_value)
        except (ValueError, TypeError):
            return None
    
    try:
        # Step 1: Ensure entities exist (using preview data when available)
        for idx, entity_data in enumerate(staging_entities):
            try:
                entity_name = _normalize_string(entity_data.get('entity_name'))
                customer_type = entity_data.get('entity_type') or 'Individual'
                cache_key = build_entity_key(entity_name, customer_type)

                if not cache_key:
                    raise ValueError("Missing entity name")

                if cache_key in entity_cache:
                    continue

                existing_entity = db.query(EntityStaging).filter(
                    EntityStaging.entity_name == entity_name,
                    EntityStaging.entity_type == customer_type,
                    EntityStaging.test_control == test_control
                ).first()

                if existing_entity:
                    entity_cache[cache_key] = existing_entity
                    entity_summary['reused'] += 1
                    continue

                new_entity = EntityStaging(
                    entity_name=entity_name,
                    entity_type=customer_type,
                    passport_photo=_normalize_string(entity_data.get('passport_photo')),
                    company_logo=_normalize_string(entity_data.get('company_logo')),
                    file_number=_normalize_string(entity_data.get('file_number')),
                    created_at=datetime.utcnow(),
                    test_control=test_control
                )

                db.add(new_entity)
                db.flush()
                entity_cache[cache_key] = new_entity
                entity_summary['new'] += 1

            except Exception as e:
                logger.error("Error creating entity from preview %d: %s", idx, str(e))
                entity_summary['failed'] += 1
                errors.append({
                    'record_index': idx,
                    'type': 'entity_error',
                    'error': str(e)
                })

        # Step 2: Persist customer staging records
        for idx, customer_data in enumerate(staging_customers):
            try:
                customer_name = _normalize_string(customer_data.get('customer_name') or customer_data.get('name'))
                if not customer_name:
                    raise ValueError("Missing customer name")

                customer_type = customer_data.get('customer_type') or 'Individual'
                entity_name = customer_data.get('entity_name')
                cache_key = build_entity_key(entity_name, customer_type)

                if not cache_key or cache_key not in entity_cache:
                    # Attempt to rebuild entity on-the-fly using original record if cache miss
                    entity_name_normalized = _normalize_string(entity_name)
                    if not entity_name_normalized:
                        raise ValueError("Unable to resolve entity for customer")

                    existing_entity = db.query(EntityStaging).filter(
                        EntityStaging.entity_name == entity_name_normalized,
                        EntityStaging.entity_type == customer_type,
                        EntityStaging.test_control == test_control
                    ).first()

                    if existing_entity is None:
                        existing_entity = EntityStaging(
                            entity_name=entity_name_normalized,
                            entity_type=customer_type,
                            file_number=_normalize_string(customer_data.get('file_number')),
                            created_at=datetime.utcnow(),
                            test_control=test_control
                        )
                        db.add(existing_entity)
                        db.flush()
                        entity_summary['new'] += 1

                    cache_key = build_entity_key(entity_name_normalized, customer_type)
                    entity_cache[cache_key] = existing_entity

                entity = entity_cache[cache_key]

                property_address = _normalize_string(customer_data.get('property_address'))
                if is_pic and not property_address:
                    district_value = customer_data.get('districtName') or customer_data.get('district')
                    lga_value = customer_data.get('LGA') or customer_data.get('lga')
                    property_address = _combine_location(district_value, lga_value)

                if is_pra and not property_address:
                    district_value = customer_data.get('districtName') or customer_data.get('district')
                    lga_value = customer_data.get('LGA') or customer_data.get('lga')
                    property_address = _combine_location(district_value, lga_value) or property_address

                notes_value = customer_data.get('notes')
                if not notes_value and is_file_history:
                    notes_value = customer_data.get('reason_by')

                created_by_value = safe_int_conversion(customer_data.get('created_by_raw'))
                file_number_value = _normalize_string(customer_data.get('file_number'))
                account_number_value = _normalize_string(customer_data.get('account_no')) or file_number_value

                customer = CustomerStaging(
                    customer_name=customer_name,
                    customer_type=customer_type,
                    customer_code=customer_data.get('customer_code') or _generate_customer_code(),
                    email=_normalize_string(customer_data.get('email')),
                    phone=_normalize_string(customer_data.get('phone')),
                    property_address=property_address,
                    residential_address=_normalize_string(customer_data.get('residential_address')),
                    notes=notes_value,
                    entity_id=entity.id,
                    created_by=created_by_value,
                    created_at=datetime.utcnow(),
                    test_control=test_control,
                    file_number=file_number_value,
                    account_no=account_number_value,
                    reason_retired=_normalize_string(customer_data.get('reason_retired'))
                )

                db.add(customer)
                customer_summary['created'] += 1

            except Exception as e:
                logger.error("Error creating customer staging %d: %s", idx, str(e))
                customer_summary['failed'] += 1
                errors.append({
                    'record_index': idx,
                    'type': 'customer_error',
                    'error': str(e)
                })
        
        db.commit()
        
        return {
            'success': len(errors) == 0,
            'entity_summary': entity_summary,
            'customer_summary': customer_summary,
            'errors': errors,
            'staging_preview_summary': staging_summary
        }
        
    except Exception as e:
        db.rollback()
        logger.error("Staging import failed: %s", str(e))
        raise
